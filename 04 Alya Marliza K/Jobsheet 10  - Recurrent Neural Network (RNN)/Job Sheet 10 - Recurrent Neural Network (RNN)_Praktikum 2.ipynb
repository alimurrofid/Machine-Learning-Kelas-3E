{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhlfjtuAszTz"
      },
      "source": [
        "# **Praktikum 2**\n",
        "\n",
        "### Generator Teks dengan RNN\n",
        "\n",
        "Praktikum ini mendemonstrasikan cara melakukan genearsi text menggunakan RNN. Dataset yang digunkan adalah dataset Shakespeare's writing from Andrej Karpathy's [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/). Jika diberikan urutan karakter dari data ini (\"Shakespear\"), latih model untuk memprediksi karakter berikutnya dalam urutan (\"e\"). Urutan teks yang lebih panjang dapat dihasilkan dengan memanggil model berulang kali.\n",
        "Note: Enable GPU acceleration to execute this notebook faster. In Colab: Runtime > Change runtime type > Hardware accelerator > GPU.\n",
        "Tutorial ini menggunakan tf.keras dan eager execution. Berikut adalah contoh output ketika model dalam tutorial ini dilatih selama 30 epoch, dan dimulai dengan prompt \"Q\":"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "KoQZr_6oszT1"
      },
      "source": [
        "QUEENE:\n",
        "I had thought thou hadst a Roman; for the oracle,\n",
        "Thus by All bids the man against the word,\n",
        "Which are so weak of care, by old care done;\n",
        "Your children were in your holy love,\n",
        "And the precipitation through the bleeding throne.\n",
        "\n",
        "BISHOP OF ELY:\n",
        "Marry, and will, my lord, to weep in such a one were prettiest;\n",
        "Yet now I was adopted heir\n",
        "Of the world's lamentable day,\n",
        "To watch the next way with his father with his face?\n",
        "\n",
        "ESCALUS:\n",
        "The cause why then we are all resolved more sons.\n",
        "\n",
        "VOLUMNIA:\n",
        "O, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, it is no sin it should be dead,\n",
        "And love and pale as any will to that word.\n",
        "\n",
        "QUEEN ELIZABETH:\n",
        "But how long have I heard the soul for this world,\n",
        "And show his hands of life be proved to stand.\n",
        "\n",
        "PETRUCHIO:\n",
        "I say he look'd on, if I must be content\n",
        "To stay him from the fatal of our country's bliss.\n",
        "His lordship pluck'd from this sentence then for prey,\n",
        "And then let us twain, being the moon,\n",
        "were she such a case as fills m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG4Pl3WgszT2"
      },
      "source": [
        "Meskipun beberapa kalimat memiliki tata bahasa, sebagian besar tidak masuk akal. Model belum mempelajari arti kata-kata, namun anggap saja:\n",
        "- Modelnya berbasis karakter. Saat pelatihan dimulai, model tidak mengetahui cara mengeja kata dalam bahasa Inggris, atau bahkan kata-kata tersebut merupakan satuan teks.\n",
        "- Struktur keluarannya menyerupai sandiwaraâ€”blok teks umumnya dimulai dengan nama pembicara, dengan huruf kapital semua mirip dengan kumpulan data.\n",
        "- Seperti yang ditunjukkan di bawah, model dilatih pada kumpulan teks kecil (masing-masing 100 karakter), dan masih mampu menghasilkan rangkaian teks yang lebih panjang dengan struktur yang koheren."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ5ZHoPbszT3"
      },
      "source": [
        "#### **Setup**\n",
        "\n",
        "**Import TensorFlow**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KcDIEByaszT3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf # Mengimpor pustaka TensorFlow ke dalam program.\n",
        "import numpy as np # Mengimpor pustaka NumPy ke dalam program\n",
        "import os # Mengimpor pustaka OS (Operating System) ke dalam program.\n",
        "import time # Mengimpor pustaka Time ke dalam program."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_RyRHMBszT4"
      },
      "source": [
        "**Download Dataset Shakespeare**\n",
        "\n",
        "Sesuaikan dengan lokasi data yang Anda punya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3iqpKyxszT4",
        "outputId": "0bf631f8-1e67-4896-b174-d94d344589fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Mengunduh kumpulan data teks dari TensorFlow Datasets. Kumpulan data ini berisi teks dari karya-karya William Shakespeare.\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4fLKA92szT4"
      },
      "source": [
        "**Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pORegrVaszT4",
        "outputId": "56021338-fce5-4944-d562-970af1e327d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpcjS0s-szT6",
        "outputId": "a0ff0a93-8e78-47fb-fd86-4f8f26226c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrMoiK7HszT8",
        "outputId": "6c6574c6-143b-4074-b16f-5aea7148f9da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QIAttx9szT8"
      },
      "source": [
        "####  **Olah Teks**\n",
        "\n",
        "**Vectorize Teks**\n",
        "\n",
        "Sebelum training, Anda perlu mengonversi string menjadi representasi numerik. tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_olMRbUszT8",
        "outputId": "bff5150d-81ae-4709-bf20-a092fdd19714"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Mengubah dua string menjadi daftar karakter individual\n",
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX2W-bbLszT9"
      },
      "source": [
        "sekarang buat tf.keras.layers.StringLookup layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lyCjSs0oszT9"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup( # Mendefinisikan sebuah lapisan StringLookup\n",
        "vocabulary=list(vocab), mask_token=None) # Mengatur kosakata yang akan digunakan untuk pemetaan karakter ke ID dan menandakan bahwa tidak ada token khusus untuk mewakili nilai yang hilang (missing value)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDrNyXLeszT9"
      },
      "source": [
        "perintah diatas mengconvert token menjadi id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apENhaoNszT9",
        "outputId": "c2b2f84b-adc3-423a-8bc1-3c92a2ee8c4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Mengkonversi urutan karakter menjadi urutan ID. Fungsi\n",
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vQP9aeLszT9"
      },
      "source": [
        "Karena tujuan tutorial ini adalah untuk menghasilkan teks, penting juga untuk membalikkan representasi ini. Untuk ini Anda dapat menggunakan kode tf.keras.layers.StringLookup(..., invert=True).\n",
        "Catatan: pada kode ini, daripada meneruskan kosakata asli yang dihasilkan dengan diurutkan(set(teks)) gunakan metode get_vocabulary() dari tf.keras.layers.StringLookup sehingga token [UNK] disetel dengan cara yang sama."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HwjHzJE7szT9"
      },
      "outputs": [],
      "source": [
        "#  Mengubah urutan integer ID kembali menjadi urutan string (karakter) yang sesuai.\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4aD-72DszT-"
      },
      "source": [
        "Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter tf.RaggedTensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL00Yk5gszT-",
        "outputId": "8ab22434-e48c-4cb7-ba07-9359c58a8399"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Mengubah nilai-nilai ID menjadi nilai-nilai karakter.\n",
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl2ULYigszT-"
      },
      "source": [
        "Anda dapat menggunakan tf.strings.reduce_join untuk menggabungkan kembali karakter menjadi string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kAa9BXvszT-",
        "outputId": "236a9dda-1ed4-42ba-c0ad-7de49679ca8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Menggabungkan string-string dalam tensor TensorFlow dan mengubah hasilnya menjadi array NumPy untuk penggunaan lebih lanjut.\n",
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tnP1SA32szT-"
      },
      "outputs": [],
      "source": [
        "# Mengubah urutan bilangan bulat (ID karakter) menjadi teks string.\n",
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o19bkS_9szT-"
      },
      "source": [
        "**Prediksi**\n",
        "\n",
        "Diberikan sebuah karakter, atau serangkaian karakter, karakter apa yang paling mungkin berikutnya? Ini adalah tugas yang harus Anda latih agar model dapat melakukannya. Masukan ke model akan berupa urutan karakter, dan Anda melatih model untuk memprediksi keluaran berupa karakter berikut pada setiap langkah waktu. Karena RNN mempertahankan keadaan internal yang bergantung pada elemen yang terlihat sebelumnya, mengingat semua karakter dihitung hingga saat ini, karakter apa selanjutnya?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17IcUzLhszT-"
      },
      "source": [
        "**Membuat Trianing Set dan Target**\n",
        "\n",
        "Selanjutnya bagilah teks menjadi contoh sequence. Setiap masukan sequence akan berisi karakter seq_length dari teks. Untuk setiap masukan sequence, target prediksi berisi teks dengan panjang yang sama, hanya digeser satu karakter ke kanan. Jadi, bagi teks menjadi beberapa bagian seq_length+1. Misalnya, seq_length adalah 4 dan teks kita adalah \"Hello\". Urutan masukannya adalah \"Hell\", dan urutan targetnya adalah \"ello\". Untuk melakukan ini, pertama-tama gunakan fungsi tf.data.Dataset.from_tensor_slices untuk mengonversi vektor teks menjadi aliran indeks karakter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REPhCgWmszT-",
        "outputId": "778dcc61-576f-46b6-d923-0d519bdd8d52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# emecah teks input text menjadi array karakter individual, menggunakan pengkodean UTF-8.\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Fj_3HGC5szT-"
      },
      "outputs": [],
      "source": [
        "# Menciptakan dataset TensorFlow baru bernama ids_dataset yang dimana dataset ini dibentuk dari tensor all_ids, dengan setiap elemen tensor menjadi satu elemen dalam dataset.\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmbwHyHLszT_",
        "outputId": "bb3d9c7a-36ef-48bc-a622-5329289c6280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan 10 elemen pertama dari dataset ids_dataset dalam bentuk teks yang dapat dibaca manusia.\n",
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Yam9OJ6HszT_"
      },
      "outputs": [],
      "source": [
        "# menetapkan panjang urutan dalam model.\n",
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCK6vL7QszT_"
      },
      "source": [
        "Metode batch memungkinkan Anda dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlWWjfhEszT_",
        "outputId": "cbb98fa1-d35c-498e-d1b4-aba8b82acd10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# Membagi dataset menjadi batch, mengambil satu batch sebagai contoh, dan mengubah ID menjadi karakter\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTcSaWGDszT_"
      },
      "source": [
        "akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m1IwFywszT_",
        "outputId": "11a51236-2515-413f-d369-755f6ffb328f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "# Mengambil 5 urutan pertama dari objek sequences dan menampilkan teks yang sesuai dengan setiap urutan.\n",
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnteNnPVszT_"
      },
      "source": [
        "Untuk pelatihan, Anda memerlukan kumpulan data pasangan (input, label). Dimana input dan label merupakan urutan. Pada setiap langkah waktu, inputnya adalah karakter saat ini dan labelnya adalah karakter berikutnya. Berikut adalah fungsi yang mengambil urutan sebagai masukan, menduplikasi, dan menggesernya untuk menyelaraskan masukan dan label untuk setiap langkah waktu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "gS-hisHmszUA"
      },
      "outputs": [],
      "source": [
        "# Memungkinkan model untuk belajar dari pola dalam data dan memprediksi nilai yang belum diketahui.\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsVl3ys3szUA",
        "outputId": "ce438c81-8452-4814-c721-57d4fda1027a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Membagi daftar menjadi dua daftar, satu untuk input dan satu untuk target. Daftar input berisi data yang akan digunakan untuk melatih model, sedangkan daftar target berisi data yang akan diprediksi oleh model.\n",
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yHusn6jdszUA"
      },
      "outputs": [],
      "source": [
        "# Membagi kumpulan data urutan menjadi dua kumpulan data, satu untuk input dan satu untuk target.\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TXNhm1yszUA",
        "outputId": "17973d0d-7784-4a5f-99cc-e83896a9ebff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "# Mengambil satu contoh dari dataset dan mencetak data input dan target dari contoh tersebut.\n",
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW6niHMsszUE"
      },
      "source": [
        "**Membuat Batch Training**\n",
        "\n",
        "Anda menggunakan tf.data untuk membagi teks menjadi sequence yang dapat diatur. Namun sebelum memasukkan data ini ke dalam model, Anda perlu mengacak data dan mengemasnya ke dalam batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3_jfK9RszUE",
        "outputId": "ee36b232-c17b-407d-8229-dd5d2f21e001"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxMVFJI8szUF"
      },
      "source": [
        "#### **Buat Model**\n",
        "\n",
        "Bagian ini mendefinisikan model sebagai subkelas keras.Model (untuk lebih detilnya, lihat [Making new Layers and Models via subclassing](https://www.tensorflow.org/guide/keras/making_new_layers_and_models_via_subclassing) ).\n",
        "Model yang kita bangun memiliki 3 lapisan neural network :\n",
        "* tf.keras.layers.Embedding: Lapisan masukan. Tabel pencarian yang dapat dilatih yang akan memetakan setiap karakter-ID ke vektor dengan dimensi embedding_dim;\n",
        "* tf.keras.layers.GRU: lapisan RNN dengan ukuran unit=rnn_units (Anda juga dapat menggunakan lapisan LSTM di sini.)\n",
        "* tf.keras.layers.Dense: Lapisan keluaran, dengan keluaran vocab_size. Ini menghasilkan satu logit untuk setiap karakter dalam kosakata. Ini adalah log kemungkinan setiap karakter menurut model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "EEojV1mAszUF"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lfjpR5EVszUF"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan model pembelajaran mesin untuk pemrosesan teks yang menggunakan lapisan embedding, lapisan GRU, dan lapisan output.\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Wyh86fqhszUF"
      },
      "outputs": [],
      "source": [
        "# Menginstansiasi model MyModel dengan parameter spesifik yang menentukan ukuran kosakata, dimensi embedding, dan jumlah unit RNN.\n",
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1caHCQVpszUF"
      },
      "source": [
        "Untuk setiap karakter, model mencari penyematan, menjalankan GRU satu langkah waktu dengan penyematan sebagai masukan, dan menerapkan dense layer untuk menghasilkan log yang memprediksi kemungkinan log karakter berikutnya:\n",
        "\n",
        "<div style=\"text-align:center\">\n",
        "\n",
        "![alt text](text_generation_training.png)\n",
        "\n",
        "</div>\n",
        "\n",
        "###### <center>A drawing of the data passing through the model</center>\n",
        "\n",
        "Note: Untuk pelatihan Anda bisa menggunakan model keras.Sequential di sini. Untuk menghasilkan teks nanti, Anda harus mengelola status internal RNN. Akan lebih mudah untuk memasukkan opsi input dan output status di awal, daripada mengatur ulang arsitektur model nanti. untuk detailnya bisa dilihat [Keras RNN Guide](https://www.tensorflow.org/guide/keras/working_with_rnns#rnn_state_reuse)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-ASBhudszUF"
      },
      "source": [
        "#### **Uji Model**\n",
        "\n",
        "Coba jalankan model dan cek apakah sidah sesuai dengan output\n",
        "pertama, cek bentuk dari output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neadDx9mszUF",
        "outputId": "117419a1-212a-4285-c8c3-eabb568732d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "# Memeriksa dan memastikan bentuk output model untuk memastikannya sesuai dengan yang diharapkan.\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylVCzGhlszUF"
      },
      "source": [
        "Dalam contoh di atas, panjang urutan masukan adalah 100 tetapi model dapat dijalankan pada masukan dengan panjang berapa pun:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iMlmqmhszUF",
        "outputId": "ecb17eb2-af83-4edc-ae07-5b1fe30d76c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan informasi tentang model pembelajaran mesin, termasuk nama dan jenis setiap lapisan, bentuk input dan output setiap lapisan, dan jumlah parameter yang dilatih dalam model.\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHoj_5kKszUF"
      },
      "source": [
        "Untuk mendapatkan prediksi aktual dari model, Anda perlu mengambil sampel dari distribusi keluaran, untuk mendapatkan indeks karakter aktual. Distribusi ini ditentukan oleh logit pada kosakata karakter. Catatan: Penting untuk mengambil sampel dari distribusi ini karena mengambil argmax dari distribusi tersebut dapat dengan mudah membuat model terjebak dalam infinote loop. Cobalah untuk contoh pertama di batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8bIgXlbrszUF"
      },
      "outputs": [],
      "source": [
        "# Mengambil sampel acak dari distribusi probabilitas dan mengubahnya menjadi bentuk yang dapat digunakan untuk pengambilan keputusan lebih lanjut.\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEV8OTJdszUG"
      },
      "source": [
        "Hal ini memberi kita, pada setiap langkah waktu, prediksi indeks karakter berikutnya:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-FGBoSdszUG",
        "outputId": "7a2cf338-27a2-4d00-b0ce-84f4024ee839"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([19, 37, 28, 53, 55, 38,  9, 57, 36, 40, 20, 56, 40,  8,  6, 13, 17,\n",
              "       10, 10, 33, 64,  8, 23, 34, 14, 49, 10, 50,  5, 26, 45, 42,  5, 62,\n",
              "       31,  8, 39, 35, 21, 24, 49, 63, 61, 37, 46, 34, 25, 46, 53, 45, 29,\n",
              "       62, 33, 51, 24, 38, 25, 41, 55,  8, 12, 28, 40, 23, 35, 40, 43, 44,\n",
              "       43,  2, 52, 63, 27, 17, 12, 27,  9, 46, 19, 17,  6,  7, 32,  2, 25,\n",
              "       30, 21,  6, 29, 26,  4, 58, 42,  5, 23, 14,  0, 47, 26,  2])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Menyimpan indeks dari data yang akan digunakan untuk melatih atau menguji mode\n",
        "sampled_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btmW-0UDszUG"
      },
      "source": [
        "Dekode kode berikut untuk melihat teks yang diprediksi oleh model tidak terlatih ini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT3sp2srszUG",
        "outputId": "4d1a6903-06f3-4c1a-f08e-497af163cee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'ility: mark his\\nbehavior. We are not to stay all together, but to\\ncome by him where he stands, by on'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"FXOnpY.rWaGqa-'?D33Ty-JUAj3k&Mfc&wR-ZVHKjxvXgULgnfPwTlKYLbp-;OaJVaded mxND;N.gFD',S LQH'PM$sc&JA[UNK]hM \"\n"
          ]
        }
      ],
      "source": [
        "# Memvisualisasikan teks input dan prediksi yang dihasilkan oleh model pembelajaran mesin yang bekerja dengan teks.\n",
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN13Vb2EszUG"
      },
      "source": [
        "#### **Train Model**\n",
        "\n",
        "Pada titik ini permasalahan dapat dianggap sebagai permasalahan klasifikasi standar. Permasalahan dapat disimpulkan dengan : Berdasarkan status RNN sebelumnya, dan masukan langkah kali ini, prediksi kelas karakter berikutnya.\n",
        "\n",
        "**Tambahan optimizer dan fungsi loss**\n",
        "\n",
        "loss function tf.keras.losses.sparse_categorical_crossentropy standar berfungsi dalam kasus ini karena diterapkan di seluruh dimensi terakhir prediksi. Karena model Anda mengembalikan logits, Anda perlu mengatur flag from_logits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5tLIPsO5szUG"
      },
      "outputs": [],
      "source": [
        "# Menetapkan fungsi kerugian untuk model pembelajaran mesin.\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnBnX36ZszUH",
        "outputId": "ad7d0e4d-f436-4a47-fdb4-e8cdee17d394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.190168, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Memeriksa prediksi model dan loss selama pelatihan model\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPjokb0SszUH"
      },
      "source": [
        "Model yang baru diinisialisasi tidak boleh terlalu yakin dengan dirinya sendiri, semua log keluaran harus memiliki besaran yang sama. Untuk mengonfirmasi hal ini, Anda dapat memeriksa bahwa eksponensial dari loss rata-rata harus kira-kira sama dengan ukuran kosakata. Loss yang jauh lebih tinggi berarti model tersebut yakin akan jawaban yang salah, dan memiliki inisialisasi yang buruk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swM8tSnlszUH",
        "outputId": "e0cbf0b8-59a4-4be5-feb0-bad6aaad4ad3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.03388"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Mengubah nilai loss dari array TensorFlow menjadi array NumPy\n",
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFgM3KWoszUH"
      },
      "source": [
        "Konfigurasikan prosedur pelatihan menggunakan metode tf.keras.Model.compile. Gunakan tf.keras.optimizers.Adam dengan argumen default dan fungsi loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "VLO2ciRZszUH"
      },
      "outputs": [],
      "source": [
        "# Mengkompilasi model\n",
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9aph7CJszUH"
      },
      "source": [
        "**Konfigurasi Checkpoints**\n",
        "\n",
        "Gunakan tf.keras.callbacks.ModelCheckpoint untuk memastikan bahwa checkpoint disimpan selama pelatihan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "LefCEDGFszUH"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z6vh-3gszUH"
      },
      "source": [
        "**Lakukan Proses Training**\n",
        "\n",
        "Agar waktu pelatihan tidak terlalu lama, gunakan 10 epoch untuk melatih model. Di Colab, setel runtime ke GPU untuk pelatihan yang lebih cepat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-b0tdh5tszUH"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP1kRk-9szUI",
        "outputId": "40135557-5e0d-4dde-e6e9-ff13bcab341a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 20s 57ms/step - loss: 2.7388\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 1.9996\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 1.7246\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.5605\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 11s 54ms/step - loss: 1.4592\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.3907\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.3383\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 12s 55ms/step - loss: 1.2924\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.2525\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.2140\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.1752\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.1365\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 12s 54ms/step - loss: 1.0941\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 12s 54ms/step - loss: 1.0495\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.0040\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 0.9540\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 0.9033\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 0.8507\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 12s 54ms/step - loss: 0.7989\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 12s 55ms/step - loss: 0.7494\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyMYfkcLszUI"
      },
      "source": [
        "#### **Generate Teks**\n",
        "\n",
        "Cara termudah untuk menghasilkan teks dengan model ini adalah dengan menjalankannya dalam loop, dan menyimpan status internal model saat Anda menjalankannya.\n",
        "\n",
        "<div style=\"text-align:center\">\n",
        "\n",
        "![alt text](text_generation_sampling.png)\n",
        "\n",
        "</div>\n",
        "\n",
        "###### <center>To generate text the model's output is fed back to the input</center>\n",
        "\n",
        "Setiap kali Anda memanggil model, Anda memasukkan beberapa teks dan state internal. Model mengembalikan prediksi untuk karakter berikutnya dan state barunya. Masukkan kembali prediksi dan state ke model untuk terus menghasilkan teks.\n",
        "\n",
        "Berikut ini membuat prediksi satu langkah:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "bxxTnBzFszUI"
      },
      "outputs": [],
      "source": [
        "#  Menghasilkan teks secara bertahap menggunakan model TensorFlow\n",
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan prediksi satu langkah demi satu langkah, yang berguna dalam tugas-tugas seperti text generation di mana model perlu menghasilkan teks secara bertahap.\n",
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "vah8FKF4wV_D"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DSvNNYgszUI"
      },
      "source": [
        "Jalankan secara berulang untuk menghasilkan beberapa teks. Melihat teks yang dihasilkan, Anda akan melihat model mengetahui kapan harus menggunakan huruf besar, membuat paragraf, dan meniru kosakata menulis seperti Shakespeare. Karena sedikitnya jumlah epoch pelatihan, model belum belajar membentuk kalimat runtut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSK7OxlrszUJ",
        "outputId": "bd997c58-f17f-4f0c-bdd4-cb029e5cd091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "This earth from this found how we loved. What praise\n",
            "As ir to breathe my thoughts as I do,\n",
            "In angry ganes, I will go slay thy life;\n",
            "You, as your son, as it is your company.\n",
            "\n",
            "CLIFFORD:\n",
            "Ay, too; and this is like a gentleman.\n",
            "I see that love but violent and his suit\n",
            "And kiss a trook of thine! that he would mouth, my soul!\n",
            "Good queen, how so? Bred thine too, unight.\n",
            "\n",
            "ANTONIO:\n",
            "And I should propared visitation;\n",
            "Conform now summon, her love I beauty;\n",
            "And that's my pown, 'Pear get at her;\n",
            "Much more than he that pleded 'gainst the stares that would\n",
            "Have run their birth, they can it is.\n",
            "\n",
            "First Lord:\n",
            "O God, this manner of his priedch,\n",
            "Would all the press't pleasure makes them send to thee.\n",
            "Ratcliff, and long to die fequer blood of further\n",
            "To open a tumpling friendly. while lie, heaven and the crown and truch\n",
            "of your own state and my brother Argoin obstable,\n",
            "Shall you din err; therefore harm to breathe.\n",
            "\n",
            "BALTHAS AUEEL:\n",
            "Bound to the master, and my good frail thou worthing here.\n",
            "\n",
            "HENRY BOLINGBROKE: \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.10894775390625\n"
          ]
        }
      ],
      "source": [
        "# Menghasilkan teks sepanjang 1000 karakter menggunakan model one_step_model. Proses dimulai dengan karakter 'ROMEO:' dan kemudian secara bertahap menghasilkan karakter berikutnya hingga mencapai 1000 karakter.\n",
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSuFthjPszUJ"
      },
      "source": [
        "Hal termudah yang dapat Anda lakukan untuk meningkatkan hasil adalah dengan melatihnya lebih lama (coba EPOCHS = 30). Anda juga dapat bereksperimen dengan string awal yang berbeda, mencoba menambahkan lapisan RNN lain untuk meningkatkan akurasi model, atau menyesuaikan parameter suhu untuk menghasilkan prediksi yang kurang lebih acak.\n",
        "\n",
        "Jika Anda ingin model menghasilkan teks lebih cepat, hal termudah yang dapat Anda lakukan adalah membuat teks secara batch. Pada contoh di bawah, model menghasilkan 5 keluaran dalam waktu yang hampir sama dengan waktu yang dibutuhkan untuk menghasilkan 1 keluaran di atas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "bDnQRDLVszUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa1a9de6-79f2-4d62-e36e-17eb6c758d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nThe duke us ratel; lean ask an ir our\\nworser backward with departing.\\n\\nMENENIUS:\\nNow, good morrow, good Lord:\\nThis our dam, dead? why, you may not add\\nTo tale a consul.\\n\\nFirst Senator:\\nMarry, sir, commend me to him lie I meld.\\n\\nDUKE VINCENTIO:\\nO Pold!\\nAppare not work: our city is as I do,\\nSome might be long.\\n\\nTONBALO:\\nMake it a son in wears her, lie thou there,\\nAnd tribl his growth fair queen; you would never dined it\\nseems as 'twere a solemn years out of it.\\nPut up your honour hear more strange.\\n\\nISABELLA:\\nLet her confess that thou murderer, and further slow.\\n\\nKING RICHARD III:\\nMadam, Boice, O, il'd you might know his name to my enterprise,\\nAnd Richard lie doth gues send to the worst of Rome!\\n\\nChildren:\\nIt was knew you: yet you mistake, sweet son:\\nThe swift resolve your honour whereoor of your daughter.\\n\\nKING RICHARD III:\\nAlack, that ever wash my daughter Kate?\\n\\nARIEL:\\nO, now I were so\\ngood, so God he beats? but I will leave you. Fare yet your honour,\\nnone, brother, your affair and l\"\n",
            " b\"ROMEO:\\nThat's I go?\\n\\nGLOUCESTER:\\nWhat, my true sea?\\nAnd thus, to dangerous, my matches to thee\\nMade York the hope to speak with Eath ban a stagger\\nAs promised here, and to this name of you\\nHow I mistaken you, and yet you will.\\n\\nANGELO:\\nWho shall his oath rebut to beat blessed blast\\nAs I can but suppose by rawn\\naimorthing; and these perform'd an leins now several strain\\nThan our nest way: down for some speech would.\\n\\nANGELO:\\nBelieve me, or shorten of my function:\\nI will prove so.:\\nWe will not ig,\\nThe raven rain'd words of some speech ochard-man.\\nO, fathers to his father's head?\\n\\nNORTHUMBERLAND:\\nNo none, sir, well, I do see what suck business\\nI should quickly. Would I had rather keep your cute\\nIntenda rest under a stabe now,\\nSave that was thine, or thou woo'ers.\\n\\nPOLIXENES:\\nHow!\\nCan he can grations, my mourning we come whose human cass:\\nHail tongue me 'Twill puts on a place but hads my fortunes of the morn;\\nAnd a die own eye, and answer touch\\nI wander through the drunkard's drum,\\nThan say, Edw\"\n",
            " b\"ROMEO:\\nI pray thee, perish! Clewners to the king's, makes on us\\nEnward, that is coming; we will to Bolingbroke,\\nIt must be granded tongue's growing:\\nMy lord, yet must I subject two enemies?\\n\\nHeirs Ladyer:\\nMake has been driven from the truth, and therefore?\\n\\nANGELO:\\nWhy, here's the matter?\\n\\nCORIOLANUS:\\nO miserable may more show them!\\n\\nCORIOLANUS:\\nHave you indeed that do?\\nWhich with conscience stoot Edward?\\n\\nCAPULET:\\nWhat man what I was born to sin? I'll make will\\nnot how her father rebuts the liard: I know not how it hands again:\\nPray, good Grumo, and here I lean the English crown.\\n\\nKING HENRY VI:\\nPardon me, God in heaven for Juliet plain,\\nI have been deserves of good, madam, indeed; nex,\\nSo content that would have leave to-morrow of their\\npart, and I could tear to pay.\\n\\nDUKE VINCENTIO:\\nNow I fear the northern, obey: I advise you:\\nI speak it any that will be reigned but the\\nsingle of it.\\n\\nPAULINA:\\nFollow me.\\n\\nClown:\\nI twice for Clarence, since this Edward, he must conjure her.\\n\\narraganet: Sig\"\n",
            " b\"ROMEO:\\nO Thouchard's hard, here come thou speak't.\\n\\nBRUTUS:\\nA life renowned vows it ill; I say.\\n\\nRICHARD:\\nArm'd against some more enough to purcu, strike, must be.\\nTo the utrengthen'd stopp's house overtake.\\n\\nSICINIUS:\\nDismin to do\\nFor them to your, in gentle brother Clardicament,\\nTo mend his death enjoy'd: some confirm\\nThat all is Elbow's man: so but I can make, Warwick.\\n\\nKING RICHARD III:\\nThey say it is your suits are zelight.\\n\\nBENVOLIO:\\nI can do you young men! prince of daily need.\\n\\nGLOUCESTER:\\nMy life, you that no more but the duke to themselves?\\n\\nGhostortable tailors.\\n\\nGRUMIO:\\nKnow, good my lord!\\n\\nPOLIXENES:\\nCall!\\nfor what I saw, the most sorrow our news?\\n\\nNORTHUMBERLAND:\\nYes, the say the men.\\nBut seily he says Henry, madam?\\n3 hable father, we were wash'd toads;\\nOne that tidors' tongues to-day my blood,\\nWhich is the base of eyes shut supplex our hands.\\nThe gates made blood'd who he smiles lighten words\\nAnd hath shows of more business'd, breathing's,\\nAnd spurning ear world's vessel, that\"\n",
            " b\"ROMEO:\\nI pray thee, part of, for my good lords and young and loud content\\nIs suffer'd bove some high;\\nAnd they are coming in his purpose.\\n\\nRIVERS:\\nWho knew so day, and so show a lover\\nThan drops cry out!\\n\\nANGELO:\\nI will be satisfied.\\n\\nKING RICHARD III:\\nWhy, how now, you consent that?\\n\\nGLOUCESTER:\\nI must talk not, or else you should draw nob any comf\\nTo speak of us, and venomous; home it frament;\\nAnd can no more stock his so too.\\n\\nPERDITA:\\nSo long a saint,\\nWe should a virtuous banish'd day\\nBefore their death was sun to fear of this sword?\\n\\nHENRY BOLINGBROKE:\\nOf that have more proud crab-or day, more known;\\nFor that's my son; these loves will meetly pieces:\\nThen you canst minister concerns me\\nHath held our general assurence of his\\nway? never good my life is dead!\\nWhere's thy name? Doubhs the reverence\\nTutors or I'll custom him from this intelcome.\\n\\nDUKE VINCENTIO:\\nBy mine on his own affairs, my mourning means but thou,\\nFair love to be inform'd me.\\n\\nANTIGONUS:\\nLook, you have one between thyself\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.915996789932251\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ogaTsOyszUJ"
      },
      "source": [
        "#### **Ekspor Model Generator**\n",
        "\n",
        "Model satu langkah ini dapat dengan mudah disimpan dan digunakan kembali, memungkinkan Anda menggunakannya di mana pun tf.saved_model diterima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "_9v1TcHIszUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756e0ab1-bec1-433e-b5cd-f765d155f56d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7d3ee0536860>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ],
      "source": [
        "# Menyimpan dan memuat kembali model pembelajaran mesin TensorFlow.\n",
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "gkx7JDtzszUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656d6429-9bc8-448b-cc84-bdd27a24f41f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "The lusts I fear me heaven, is spirit how her frightful wheel\n",
            "To stop out of a woment, an hear met \n"
          ]
        }
      ],
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}